\documentclass[a4paper,12pt]{report}

\usepackage{amsmath,amsfonts,mathtools}
\usepackage{amsbsy}
\usepackage{hyperref}

\begin{document}
\title{MAT292 Abridged}
\author{Aman Bhargava}
\date{September 2019}
\maketitle

\tableofcontents

\section{Introduction}
The textbook and lectures for this course offer a great comprehensive guide for the 
methods of solving ODE's. The goal here is to give a very concise overview of the things you 
need to know (NTK) to answer exam questions. Unlike
some of our other courses, you don't need to be very intimately familiar with the derivations
of everything in order to solve the problems (though it certainly doesn't hurt). Think of this 
as a really good cheat sheet.

\chapter{Qualitative Things and Definitions}
\section{Definitions}
\begin{enumerate}
\item \textbf{Differential Equation: } Any equation that contains a differential of dependent variable(s) with respect to any independent variable(s)
\item \textbf{Order: } The order of the highest derivative present.
\item \textbf{Autonomous: } When the definition of the $\frac{dy}{dt}$ doesn't contain $t$
\item \textbf{ODE and PDE: } Ordinary derivatives or partial derivatives. 
\item \textbf{Linear Differential Equations: } $n$th order Linear ODE is of the form: $$\sum a_i(t)y^{(i)} = 0$$
\item \textbf{Homogenous: } if the $0$th element of the above sum has $a_0(t) = 0$ for all $t$. 
\end{enumerate}


\section{Qualitative Analytic Methods to Know}
\begin{enumerate}
\item Phase lines
\item Slope fields
\end{enumerate}

\section{Types of Equilibrium}
\begin{enumerate}
\item Asymptotic stable equilibrium 
\item Unstable equilibrium 
\item Semistable equilibirium
\end{enumerate}

\chapter{1st Order ODE's}
\section{Separable 1st Order ODE's}
If you can write the ODE as: $$\frac{dy}{dx} = p(x)q(y)$$

Then you can put $p(x)$ with $dx$ on one side and $q(y)$ with  $dy$ on the other and 
integrate them both so solve the ODE.

\section{Method of Integrating Factors}
This is used to solve ODE's that can be put into the form 
$$\frac{dy}{dt} + p(t)*y = g(t)$$

The chain rule can be written as: $\int (f'(x)g(x) + f(x)g'(x)) dx =  f(x)g(x)$

We can use an \textbf{integrating factor} equivalent to $e^{\int p(t) dt}$ to multiply
both sides and arrive at a form that can be integrated with ease using the reverse chain 
rule.

\section{Exact Equations}
If the equation is of the form $$M(x, y) + N(x, y) \frac{dy}{dx} = 0$$
and $$M_y(x, y) = N_x(x, y)$$ 
then $\exists$ a function $f$ satistfying $$f_x(x, y) = M(x, y); f_y(x, y) = N(x, y)$$

\paragraph{The solution: } $f(x, y) = C$ where $C$ is an arbitrary constant.

\section{Modeling with First Order Equations}
These are some vague tips on how to solve these types of problems from textbook section 
2.3
\begin{itemize}
\item To \textbf{create} the equation, state physical principles
\item To \textbf{solve}, solve the equation and/or find out as much as you can about the nature of the solution.
\item Try \textbf{comparing} the solution/equation to the physical phenomenon to `check' your work.
\end{itemize}

\section{Non-Linear vs. Linear DE's}
\paragraph{Theorem on Uniqueness of 1st Order Solutions}
$$y' + p(t)y = g(t)$$
There exists a unique solution $y=\Phi(t)$ for each starting point $(y_0, t_0)$ if 
$p$, $g$ are continuous on the given interval.

\section{Population Dynamcis with Autonomous Equations}
\paragraph{Autonomous: } $\frac{dy}{dt} = f(y)$

\subsection{Simple Exponential}
$\frac{dy}{dt} = ry$
Problem: doesn't take into account the upper bound for population/sustainability.

\subsection{Logistic equation}
$$\frac{dy}{dt} = (r-ay)y$$
Equivalent form: 
$$\frac{dy}{dt} = r(1 - \frac{y}{k})y$$
$f$ is the \textit{intrinsic growth rate}.







\chapter{Systems of Two 1st Order DE's}
\section{Set Up}
Your first goal is to get the system in the form $$\frac{d \pmb{u}}{dt} = \pmb{Ku + b}$$
Where $\pmb{K}$ is a 2 by 2 matrix, $\pmb{u}$ is your vector of values you want to 
predict, and $\pmb{b}$ is a $2$-long vector of constants.

\paragraph{More generally, } the equation is of the type 
$$\frac{d\pmb{x}}{dt} = \pmb{P}(t)x + \pmb{g}(t)$$

Called a \textbf{first order linear system of two dimensions}. If $\pmb{g}(t) = \pmb{0} \forall t$ 
then it is called \textbf{homogenous}, else \textbf{non-homogenous}. We let $x$ be composed
of values $$\pmb{x} = \begin{bmatrix}
                           x \\
                           y \\
                      \end{bmatrix}$$

\section{Existence and Uniqueness of Solutions}
\paragraph{Theorem: } $\exists$ unique solution to $$\frac{d\pmb{x}}{dt} = \pmb{P}(t)x + \pmb{g}(t)$$ 
so long as the functions $\pmb{P}(t)$ exist and are continuous on the interval $I$ in equestion.

\subsection{Linear Autonomous Systems}
If the right side doesn't depend on $t$, it's autonomous. In this case, the autonomous 
version looks (familiarly) like: $$\frac{d\pmb{x}}{dt} = \pmb{A}x + \pmb{b}$$

\paragraph{Equilibrium points} arise when $\pmb{A}x = -\pmb{b}$

\section{Solving}
\subsection{General Solution}
We start with $y' = \pmb{A}y+b$
\begin{itemize}
\item Find eigen values $\lambda$ s.t. $det(A-I\lambda) = 0$
\item Find eigen vectors $v$ s.t. $(A-I\lambda)v = 0$
\item Enter and simplify $y(t) = C_1 v_1 e^{\lambda_1 t} + C_2 v_2 e^{\lambda_2 t}$
\end{itemize}
\paragraph{Converting to homogenous equation: } Let $y_{eq}$ be the equilibrium value of $y$ that 
can be found when $y' = 0 = Ay + b$. 
$$y_{eq} + \bar{y} = y$$ and $y_{eq}$ is the solution to $\bar{y}' = A\bar{y}$.


\subsection{Special Case 1: Repeated Eigen Value}
Start in the same fashion as above. You will easily be able to find the eigen value and 
at least one eigen vector. Then, the path diverges:

\paragraph{Case 1: Another can easily be found - } Now you find your $v_2$ and proceed.

\paragraph{Case 2: Another cannot easily be found - } You must use the following formula 
to find your second vector if this is the case:
$$(A-I\lambda)v_2 = v_1$$
This is known as the "general" eigen vector.

\subsubsection{Final Form}
Your final form for this case is going to be rather different than the others:
$$x = C_1e^{\lambda_1 t}tv_1 + C_2e^{\lambda_2 t}v_2$$

\subsection{Special Case 2: Two Complex Eigen Values}

\chapter{Numerical Methods}
$$\frac{dy}{dt} = f(t, y)$$
\section{Euler's Method}
We start with a first order ODE. Let us define a fixed step $\Delta t$.
$$y_{n+1} = y_n + \Delta t(f(t_n, y_n))$$
Error = $|y(t_n)-y_n| \approx \Delta t$

\subsection{Basic Idea: Integrate The ODE}
$$\int_{t_n}^{t_n+1} \frac{dy}{dt} dt = \int_{t_n}^{t_n+1} f(t, y(t)) dt$$
Euler's method makes the following approximation.
$$\int_{t_n}^{t_n+1} f(t, y(t)) dt \approx \Delta t f(t_n, y_n)$$
But we can do better.

\subsubsection{Mean Value Theorem for Integrals}
If y is continuous on $[a, b]$ then $\exists c \in (a, b)$ so that 
$$\frac{1}{b-a} \int_a^b g(t) dt = g(c)$$
 
Euler's method would just assume that $g(c)$ is at the far left hand side of the 
Riemann sum, so we can improve upon this! If we can guess $c$ more accurately, 
our final answer will be a lot better.

\paragraph{Since $c$} is more likely to be inside the interval $[t_n, t_{n+1}$, we could 
try the following estimations to improve upon Euler's method. We will now try \textbf{sampling}.

\section{Improved Euler Method}
Let $g(t) = f(t, y(t))$. We literally use that riemann sum trapezoidal rule for this approximation.

$$y_{n+1}-y_n \approx \frac{\Delta t}{2}(f(t_n, y_n)+f(t_{n+1}, y_{n+1}))$$
Where we make the approximation for $y_{n+1}$ as
$$y_{n+1} \approx y_n + \Delta t f(t_{n+1}, y_n)$$

\paragraph{Steps: }
\begin{itemize}
\item Evaluate $K_1 = f(t_n, y_n)$
\item Predict $u_{n+1} = y_n + \Delta t K_1$
\item Evaluate $K_2 = f(t_{n+1}, u_{n+1})$
\item Update $u_{n+1} = u_n + \Delta t \frac{k_1+k_2}{2}$
\end{itemize}

This method is consider \textbf{second order}, so $$|y(t_n)-y_n| \approx C(\Delta t)^2$$ (global error). 

\paragraph{The expense } of a numerical method is roughly the \textbf{number of function calls to $f()$}. 
Therefore, improved Euler's method comes at the cost of one more function evaluation of $f()$. 

\section{Runge Kutta Method}
Modern workhorse of solving ODE's. It's 4th order, so requires 4 function $f$ calls.

\paragraph{Steps}
\begin{itemize}
\item $k_1 = f(t_n, y_n)$
\item $u_n = y_n + \frac{\Delta t}{2} k_1$ (half step)
\item $k_2 = f(t_n + \frac{\Delta t}{2}, u_n$
\item $v_n = y_n + \frac{\Delta t}{2} k_2$
\item $k_3 = f(t_n+\frac{\Delta t}{2}, v_n$
\item $w_n = y_n + \Delta t k_3$
\item $k_{-1} = f(t_{n+1}, w_n$
\item $y_{n+1} = y_n + \Delta t(\frac{k_1}{6}+\frac{k_2}{3}+\frac{k_3}{3}+\frac{k_4}{6}$
\end{itemize}

\section{Above and Beyond 4th Order}
If we can just increase our accuracy by adding more functional evaluations, then why can't we just keep on 
adding function evaluations and increasing the order?

\begin{tabular}{l|llllllllll}
\textbf{Order} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline
\textbf{Min Function Evaluations} & 1 & 2 & 3 & 4 & \textbf{6} & 7 & \textbf{9} & 11 & 14 & ? \\
\end{tabular}

Answer: Past a 4 evaluations, it's not really worth while.



\end{document}